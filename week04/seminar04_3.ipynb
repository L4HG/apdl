{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffuHOST6CsLm"
   },
   "source": [
    "# Language Modeling\n",
    "\n",
    "In this seminar we will train LM on a collection of names and try to generate new names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "from itertools import islice\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTT2uW5xCsLu"
   },
   "source": [
    "## Load data\n",
    "The dataset contains ~8k names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.701832Z",
     "start_time": "2018-08-13T20:26:42.697766Z"
    },
    "id": "dhFyOX6PCsLv"
   },
   "outputs": [],
   "source": [
    "# so that the network knows that we're generating a first token\n",
    "start_token = \"<SOS>\"\n",
    "stop_token = \"<EOS>\"\n",
    "\n",
    "# this is the token for padding,\n",
    "# we will add fake pad token at the end of names \n",
    "# to make them of equal size for further batching\n",
    "pad_token = \"<PAD>\"\n",
    "\n",
    "with open(\"names.txt\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [name.lower() for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.707885Z",
     "start_time": "2018-08-13T20:26:42.703302Z"
    },
    "id": "Kf43mc6CCsLv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 7944\n",
      "abagael\n",
      "claresta\n",
      "glory\n",
      "liliane\n",
      "prissie\n",
      "geeta\n",
      "giovanne\n",
      "piggy\n"
     ]
    }
   ],
   "source": [
    "print('number of samples:', len(names))\n",
    "for x in names[::1000]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.857411Z",
     "start_time": "2018-08-13T20:26:42.709371Z"
    },
    "id": "72rNxCG9CsLv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 15\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length:\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names)), bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3VEZIuHCsLv"
   },
   "source": [
    "## Text processing\n",
    "\n",
    "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.864592Z",
     "start_time": "2018-08-13T20:26:42.858725Z"
    },
    "id": "CLCx5pkcCsLw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_tokens =  32\n"
     ]
    }
   ],
   "source": [
    "tokens = set([\n",
    "    c\n",
    "    for name in names\n",
    "    for c in name\n",
    "])\n",
    "tokens = list(tokens)\n",
    "tokens.extend([start_token, pad_token, stop_token])\n",
    "\n",
    "num_tokens = len(tokens)\n",
    "print ('num_tokens = ', num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.870330Z",
     "start_time": "2018-08-13T20:26:42.866135Z"
    },
    "id": "9AxRKAp0CsLx"
   },
   "outputs": [],
   "source": [
    "token2index = {token: index for index, token in enumerate(tokens)}\n",
    "index2token = {index: token for token, index in token2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = lambda name: [token2index[c] for c in name]\n",
    "decoding = lambda x: \"\".join([index2token[i] for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.883107Z",
     "start_time": "2018-08-13T20:26:42.877186Z"
    },
    "id": "kyBkrX0BCsLx"
   },
   "outputs": [],
   "source": [
    "assert decoding(tokenizer('adgfdfknsa')) == 'adgfdfknsa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, names):\n",
    "        self.names = names\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return tokenizer(self.names[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Collator:\n",
    "    \n",
    "    def __init__(self, pad_value, sos_value, eos_value):\n",
    "        self.pad_value = pad_value\n",
    "        self.sos_value = sos_value\n",
    "        self.eos_value = eos_value\n",
    "    \n",
    "    def __call__(self, names):\n",
    "        max_length = 0\n",
    "        lengths = []\n",
    "        \n",
    "        for name in names:\n",
    "            max_length = max(max_length, len(name))\n",
    "            lengths.append(len(name) + 2)\n",
    "\n",
    "        output = torch.zeros(len(names), max_length + 2).long().fill_(self.pad_value)\n",
    "        for i, name in enumerate(names):\n",
    "            output[i, 0] = self.sos_value\n",
    "            output[i, 1:1 + len(name)] = torch.tensor(name)\n",
    "            output[i, 1 + len(name)] = self.eos_value\n",
    "        \n",
    "        return output, torch.tensor(lengths).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NameDataset(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = Collator(\n",
    "    pad_value=token2index[pad_token],\n",
    "    sos_value=token2index[start_token],\n",
    "    eos_value=token2index[stop_token]\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=32, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[29, 24, 26, 24, 11, 24,  2, 13, 31, 30],\n",
       "         [29, 24, 26, 24, 11, 24, 27, 13, 31, 30],\n",
       "         [29, 24, 26, 26,  2, 31, 30, 30, 30, 30],\n",
       "         [29, 24, 26, 26,  2, 18, 31, 30, 30, 30],\n",
       "         [29, 24, 26, 26, 27, 31, 30, 30, 30, 30],\n",
       "         [29, 24, 26, 26, 27,  2, 31, 30, 30, 30],\n",
       "         [29, 24, 26, 26, 18, 31, 30, 30, 30, 30],\n",
       "         [29, 24, 26, 27, 11, 24,  2, 13, 31, 30],\n",
       "         [29, 24, 26, 27, 11, 24, 27, 13, 31, 30],\n",
       "         [29, 24, 26, 27, 11, 24, 13,  2, 31, 30],\n",
       "         [29, 24, 26,  9, 24, 31, 30, 30, 30, 30],\n",
       "         [29, 24, 10, 24, 10, 27, 24, 31, 30, 30],\n",
       "         [29, 24, 23, 24, 31, 30, 30, 30, 30, 30],\n",
       "         [29, 24, 23, 24,  4, 31, 30, 30, 30, 30],\n",
       "         [29, 24, 23, 24, 13, 27, 16,  2, 31, 30],\n",
       "         [29, 24, 23, 24,  9, 24, 31, 30, 30, 30],\n",
       "         [29, 24, 23, 23, 27,  2, 31, 30, 30, 30],\n",
       "         [29, 24, 23, 23, 27, 21, 31, 30, 30, 30],\n",
       "         [29, 24, 23,  2, 13, 31, 30, 30, 30, 30],\n",
       "         [29, 24, 23,  2, 13, 24, 31, 30, 30, 30],\n",
       "         [29, 24, 23,  2, 13, 24, 27, 23,  2, 31],\n",
       "         [29, 24, 23,  2, 13,  2, 31, 30, 30, 30],\n",
       "         [29, 24, 23,  2, 13, 27, 10,  2, 31, 30],\n",
       "         [29, 24, 23,  2, 13, 27, 16, 24, 31, 30],\n",
       "         [29, 24, 23,  2, 13, 27, 16, 23, 31, 30],\n",
       "         [29, 24, 23,  2, 13, 27, 16,  2, 31, 30],\n",
       "         [29, 24, 23,  2, 13, 13, 24, 31, 30, 30],\n",
       "         [29, 24, 23,  2, 13, 13,  2, 31, 30, 30],\n",
       "         [29, 24, 23,  2, 16, 24, 31, 30, 30, 30],\n",
       "         [29, 24, 23,  2, 18, 31, 30, 30, 30, 30],\n",
       "         [29, 24, 23, 27, 31, 30, 30, 30, 30, 30],\n",
       "         [29, 24, 23, 27, 24, 16, 24, 31, 30, 30]]),\n",
       " tensor([ 9,  9,  6,  7,  6,  7,  6,  9,  9,  9,  6,  8,  5,  6,  9,  7,  7,  7,\n",
       "          6,  7, 10,  7,  9,  9,  9,  9,  8,  8,  7,  6,  5,  8]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(islice(dataloader, 1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<SOS>abagail<EOS><PAD>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoding(list(islice(dataloader, 1))[0][0][1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<SOS>abbe<EOS><PAD><PAD><PAD><PAD>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoding(list(islice(dataloader, 1))[0][0][2].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralLM(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        num_embeddings : int,\n",
    "        embedding_dim : int,\n",
    "        padding_index: int,\n",
    "        hidden_dim: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim=embedding_dim, padding_idx=padding_index)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.clf = nn.Linear(hidden_dim, embedding_dim)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        embeddings = self.embedding(input)\n",
    "        output, _ = self.rnn(embeddings)\n",
    "        logits = self.clf(output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralLM(\n",
       "  (embedding): Embedding(32, 32, padding_idx=30)\n",
       "  (rnn): LSTM(32, 64, batch_first=True)\n",
       "  (clf): Linear(in_features=64, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralLM(len(token2index), 32, token2index[pad_token], 64)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xs6EJtCyCsL0"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 10\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = NeuralLM(len(token2index), 32, token2index[pad_token], 128).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=token2index[pad_token])\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at 0 epoch: 2.6590297375338143\n",
      "Train loss at 1 epoch: 2.3692634919561057\n",
      "Train loss at 2 epoch: 2.283340691083885\n",
      "Train loss at 3 epoch: 2.2283065850476182\n",
      "Train loss at 4 epoch: 2.1865232062627036\n",
      "Train loss at 5 epoch: 2.1516691374491494\n",
      "Train loss at 6 epoch: 2.1213435006428916\n",
      "Train loss at 7 epoch: 2.0942566351718215\n",
      "Train loss at 8 epoch: 2.069476763407389\n",
      "Train loss at 9 epoch: 2.0464242672824478\n",
      "Train loss at 10 epoch: 2.0247821338684204\n",
      "Train loss at 11 epoch: 2.004177553586692\n",
      "Train loss at 12 epoch: 1.9844787297957394\n",
      "Train loss at 13 epoch: 1.9655722944612004\n",
      "Train loss at 14 epoch: 1.9474588986860222\n",
      "Train loss at 15 epoch: 1.9300515599040142\n",
      "Train loss at 16 epoch: 1.91341442707552\n",
      "Train loss at 17 epoch: 1.8975537680239083\n",
      "Train loss at 18 epoch: 1.8820934377042164\n",
      "Train loss at 19 epoch: 1.867173293029448\n",
      "Train loss at 20 epoch: 1.852798933963699\n",
      "Train loss at 21 epoch: 1.8387410300802514\n",
      "Train loss at 22 epoch: 1.82504554493839\n",
      "Train loss at 23 epoch: 1.8118234532903954\n",
      "Train loss at 24 epoch: 1.7989978163117863\n",
      "Train loss at 25 epoch: 1.7866138727310672\n",
      "Train loss at 26 epoch: 1.774723679665102\n",
      "Train loss at 27 epoch: 1.7633239734603698\n",
      "Train loss at 28 epoch: 1.7523934127815277\n",
      "Train loss at 29 epoch: 1.7418560244472152\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    \n",
    "    train_loss_meter = AverageMeter()\n",
    "    \n",
    "    for texts, text_lengths in dataloader:\n",
    "        texts = texts.to(DEVICE)\n",
    "        \n",
    "        logits = model(texts[..., :-1]).transpose(-1, -2)\n",
    "        loss = criterion(logits, texts[..., 1:])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss_meter.update(loss.item())\n",
    "    \n",
    "    print(f'Train loss at {epoch} epoch: {train_loss_meter.avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prefix='<SOS>', max_length=12):\n",
    "#     prefix_sos = prefix[:len('<SOS>')]\n",
    "    prefix = prefix[len('<SOS>'):]\n",
    "    \n",
    "    indexes = [token2index['<SOS>']] + tokenizer(prefix)\n",
    "    indexes = torch.tensor(indexes)[None, :].long()\n",
    "    \n",
    "    while len(indexes[0]) <= max_length:\n",
    "        with torch.no_grad():\n",
    "            probs = torch.softmax(model(indexes)[0, -1], dim=0)\n",
    "\n",
    "            next_token_distr = torch.distributions.Categorical(probs=probs)\n",
    "            new_token = next_token_distr.sample().item()\n",
    "        \n",
    "        indexes = indexes.tolist()[0]\n",
    "        indexes.append(new_token)\n",
    "        indexes = torch.tensor(indexes)[None, :].long()\n",
    "        \n",
    "        if new_token == token2index['<EOS>']:\n",
    "            break\n",
    "    \n",
    "    return decoding(indexes.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<SOS>mashy<EOS>'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate('<SOS>mash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "week05_generating_names_with_rnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
